{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IS_POSITION_BASED = True\n",
    "# IS_POSITION_BASED = int(sys.argv[1])\n",
    "image_size = 32\n",
    "image_channels = 3\n",
    "if IS_POSITION_BASED:\n",
    "    image_channels = 5\n",
    "num_classes = 10\n",
    "epochs = 500\n",
    "data_augmentation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx, ny = (32, 32)\n",
    "xt = np.linspace(0, 1, nx)\n",
    "yt = np.linspace(0, 1, ny)\n",
    "xpos, ypos = np.meshgrid(xt, yt)\n",
    "\n",
    "def xy_pos_add(images):\n",
    "    processed_images = []\n",
    "    count = 1\n",
    "    for image in images:\n",
    "        # print str(count) + \"/\" + str(len(images))\n",
    "        image = np.reshape(image, (32, 32, 3))\n",
    "        img = np.swapaxes(np.swapaxes(x_train[0], 0, 2), 1, 2)\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        if IS_POSITION_BASED:\n",
    "            asd = np.swapaxes(np.swapaxes(np.array(np.concatenate([[img[0]],[img[1]], [img[2]], [xpos], [ypos]])), 0, 1), 1, 2)\n",
    "        else:\n",
    "            asd = image\n",
    "        processed_images.append(asd)\n",
    "        count = count + 1\n",
    "    return np.array(processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train shape:', (50000, 32, 32, 3))\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x_train = xy_pos_add(x_train)\n",
    "new_x_test = xy_pos_add(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABELS = {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer', 5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "new_y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model defination\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Input, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "`load_weights` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-0a15c57ec690>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_vgg16_conv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"imagenet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_vgg16_conv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/applications/vgg16.pyc\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     \u001b[0mWEIGHTS_PATH_NO_TOP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                                     cache_subdir='models')\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'theano'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mlayer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_all_kernels_in_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   2563\u001b[0m         \"\"\"\n\u001b[1;32m   2564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2565\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2566\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: `load_weights` requires h5py."
     ]
    }
   ],
   "source": [
    "model_vgg16_conv = VGG16(weights=\"imagenet\", include_top=False)\n",
    "model_vgg16_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# graph setup\n",
    "img_input = Input(shape=(image_size, image_size, image_channels), name=\"input_image\")\n",
    "output_vgg16_conv = model_vgg16_conv(img_input)\n",
    "\n",
    "x = Flatten(name = 'flatten')(output_vgg16_conv)\n",
    "x = Dense(4096, activation='relu', name='layer1')(x)\n",
    "x = Dense(4096, activation = 'relu', name='layer2')(x)\n",
    "x = Dense(1024, activation = 'relu', name='layer3')(x)\n",
    "oput = Dense(10, activation = 'softmax', name='output')(x)\n",
    "\n",
    "model = Model(input=img_input, output=oput)\n",
    "model.summary()\n",
    "my_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create direct..\n",
    "if not os.path.exists(\"..results\"):\n",
    "    os.mkdir(\"../results\")\n",
    "    os.mkdir(\"../results/position\")\n",
    "    os.mkdir(\"../results/position/best_models\")\n",
    "    os.mkdir(\"../results/normal\")\n",
    "    os.mkdir(\"../results/normal/best_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checkpoints and logs\n",
    "\n",
    "if IS_POSITION_BASED:\n",
    "    checkpointer = ModelCheckpoint(filepath=\"../results/position/best_models/fn_model.{epoch:02d}-{val_acc:.6f}.hdf5\", verbose=1, monitor='val_acc', save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "    tf_board = TensorBoard(log_dir='../results/position/logs', histogram_freq=0, write_graph=True, write_images=True)\n",
    "    csv_logger = CSVLogger('../results/position/training.log')\n",
    "else :\n",
    "    checkpointer = ModelCheckpoint(filepath=\"../results/normal/best_models/fn_model.{epoch:02d}-{val_acc:.6f}.hdf5\", verbose=1, monitor='val_acc', save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "    tf_board = TensorBoard(log_dir='../results/normal/logs', histogram_freq=0, write_graph=True, write_images=True)\n",
    "    csv_logger = CSVLogger('../results/normal/training.log')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model fitting\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split=0.05,\n",
    "              callbacks=[early_stopping, checkpointer, tf_board, csv_logger],\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_split = 0.05,\n",
    "                        callbacks=[early_stopping, checkpointer, tf_board, csv_logger])\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing network\n",
    "if IS_POSITION_BASED:\n",
    "    model.save(\"./results/position/best_models/final_model_vgg16.hdf5\")\n",
    "    score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "    resultsfile = open(\"./results/position/results.txt\", 'w')\n",
    "    resultsfile.write(\"test_acc: \"+str(acc)+\"\\n\")\n",
    "    resultsfile.write(\"test_score: \" + str(score))\n",
    "    resultsfile.close()\n",
    "else:\n",
    "    model.save(\"./results/normal/best_models/final_model_vgg16.hdf5\")\n",
    "    score, acc = my_model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "    resultsfile = open(\"./results/normal/results.txt\", 'w')\n",
    "    resultsfile.write(\"test_acc: \"+str(acc)+ \"\\n\")\n",
    "    resultsfile.write(\"test_score: \"+str(score))\n",
    "    resultsfile.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
