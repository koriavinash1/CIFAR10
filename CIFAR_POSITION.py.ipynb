{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IS_POSITION_BASED = False\n",
    "# IS_POSITION_BASED = int(sys.argv[1])\n",
    "image_size = 32\n",
    "batch_size = 5\n",
    "image_channels = 3\n",
    "if IS_POSITION_BASED:\n",
    "    image_channels = 3\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "data_augmentation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx, ny = (32, 32)\n",
    "xt = np.linspace(0, 1, nx)\n",
    "yt = np.linspace(0, 1, ny)\n",
    "xpos, ypos = np.meshgrid(xt, yt)\n",
    "\n",
    "def xy_pos_add(images):\n",
    "    processed_images = []\n",
    "    count = 1\n",
    "    for image in images:\n",
    "        # print str(count) + \"/\" + str(len(images))\n",
    "        image = np.reshape(image, (32, 32, 3))\n",
    "        img = np.swapaxes(np.swapaxes(x_train[0], 0, 2), 1, 2)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        if IS_POSITION_BASED:\n",
    "            # asd = np.swapaxes(np.swapaxes(np.array(np.concatenate([[img[0]],[img[1]], [img[2]], [xpos], [ypos]])), 0, 1), 1, 2)\n",
    "            asd = np.swapaxes(np.swapaxes(np.array(np.concatenate([[image], [xpos], [ypos]])), 0, 1), 1, 2)\n",
    "        else:\n",
    "            # asd = image\n",
    "            asd = np.swapaxes(np.swapaxes(np.array([image,]*3), 0, 1), 1, 2)\n",
    "        processed_images.append(asd)\n",
    "        count = count + 1\n",
    "    return np.array(processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train shape:', (50000, 32, 32, 3))\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_x_train = xy_pos_add(x_train)\n",
    "new_x_test = xy_pos_add(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# LABELS = {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer', 5:'dog',\n",
    "\n",
    "# 6:'frog', 7:'horse', 8:'ship', 9:'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "new_y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize data\n",
    "new_x_train = new_x_train.astype('float32')\n",
    "new_x_test = new_x_test.astype('float32')\n",
    "new_x_train /= 255\n",
    "new_x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model defination\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Input, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg16_conv = VGG16(weights=\"imagenet\", include_top=False)\n",
    "model_vgg16_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_image (InputLayer)     (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 21,021,514\n",
      "Trainable params: 21,021,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ou..., inputs=Tensor(\"in...)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# graph setup\n",
    "img_input = Input(shape=(image_size, image_size, image_channels), name=\"input_image\")\n",
    "output_vgg16_conv = model_vgg16_conv(img_input)\n",
    "\n",
    "x = Flatten(name = 'flatten')(output_vgg16_conv)\n",
    "x = Dense(4096, activation='relu', name='layer1')(x)\n",
    "# x = Dense(4096, activation = 'relu', name='layer2')(x)\n",
    "x = Dense(1024, activation = 'relu', name='layer3')(x)\n",
    "oput = Dense(10, activation = 'softmax', name='output')(x)\n",
    "\n",
    "model = Model(input=img_input, output=oput)\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create direct..\n",
    "if not os.path.exists(\"../results\"):\n",
    "    os.mkdir(\"../results\")\n",
    "    os.mkdir(\"../results/position\")\n",
    "    os.mkdir(\"../results/position/best_models\")\n",
    "    os.mkdir(\"../results/normal\")\n",
    "    os.mkdir(\"../results/normal/best_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checkpoints and logs\n",
    "\n",
    "if IS_POSITION_BASED:\n",
    "    checkpointer = ModelCheckpoint(filepath=\"../results/position/best_models/fn_model.{epoch:02d}-{val_acc:.6f}.hdf5\", verbose=1, monitor='val_acc', save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "    tf_board = TensorBoard(log_dir='../results/position/logs', histogram_freq=0, write_graph=True, write_images=True)\n",
    "    csv_logger = CSVLogger('../results/position/training.log')\n",
    "else :\n",
    "    checkpointer = ModelCheckpoint(filepath=\"../results/normal/best_models/fn_model.{epoch:02d}-{val_acc:.6f}.hdf5\", verbose=1, monitor='val_acc', save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "    tf_board = TensorBoard(log_dir='../results/normal/logs', histogram_freq=0, write_graph=True, write_images=True)\n",
    "    csv_logger = CSVLogger('../results/normal/training.log')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/1\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 14.4448 - acc: 0.1038Epoch 00000: val_acc improved from -inf to 0.09958, saving model to ../results/normal/best_models/fn_model.00-0.099578.hdf5\n",
      "10000/10000 [==============================] - 4757s - loss: 14.4443 - acc: 0.1038 - val_loss: 14.5131 - val_acc: 0.0996\n"
     ]
    }
   ],
   "source": [
    "# model fitting\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(new_x_train, new_y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split=0.05,\n",
    "              callbacks=[early_stopping, checkpointer, tf_board, csv_logger],\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(new_x_train[:5000])\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(new_x_train[:5000], new_y_train[:5000], batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                        validation_data = (new_x_train[5000:], new_y_train[5000:]),\n",
    "                        callbacks=[early_stopping, checkpointer, tf_board, csv_logger])\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing network\n",
    "if IS_POSITION_BASED:\n",
    "    model.save(\"./results/position/best_models/final_model_vgg16.hdf5\")\n",
    "    score, acc = model.evaluate(new_x_test, new_y_test, batch_size=batch_size)\n",
    "    resultsfile = open(\"./results/position/results.txt\", 'w')\n",
    "    resultsfile.write(\"test_acc: \"+str(acc)+\"\\n\")\n",
    "    resultsfile.write(\"test_score: \" + str(score))\n",
    "    resultsfile.close()\n",
    "else:\n",
    "    model.save(\"./results/normal/best_models/final_model_vgg16.hdf5\")\n",
    "    score, acc = model.evaluate(new_x_test, new_y_test, batch_size=batch_size)\n",
    "    resultsfile = open(\"./results/normal/results.txt\", 'w')\n",
    "    resultsfile.write(\"test_acc: \"+str(acc)+ \"\\n\")\n",
    "    resultsfile.write(\"test_score: \"+str(score))\n",
    "    resultsfile.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
