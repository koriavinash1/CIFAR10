{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, AveragePooling2D, Dropout, Activation, Input, concatenate, Flatten, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IS_POSITION_BASED = True\n",
    "# IS_POSITION_BASED = int(sys.argv[1])\n",
    "image_size = 32\n",
    "batch_size = 10\n",
    "image_channels = 3\n",
    "if IS_POSITION_BASED:\n",
    "    image_channels = 5\n",
    "num_classes = 10\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_POSITION_BASED:\n",
    "    nx, ny = (32, 32)\n",
    "    xt = np.linspace(0, 1, nx)\n",
    "    yt = np.linspace(0, 1, ny)\n",
    "    xpos, ypos = np.meshgrid(xt, yt)\n",
    "    trainX = np.swapaxes(np.swapaxes(trainX, 0, 3), 1, 3)\n",
    "    trainX = np.swapaxes(np.swapaxes(np.swapaxes(np.vstack([[trainX[0]], [trainX[1]], [trainX[2]], [[xpos,]*trainX.shape[1]], [[ypos,]*trainX.shape[1]]]), 0, 2), 0, 1), 2, 3)\n",
    "    testX = np.swapaxes(np.swapaxes(testX, 0, 3), 1, 3)\n",
    "    testX = np.swapaxes(np.swapaxes(np.swapaxes(np.vstack([[testX[0]], [testX[1]], [testX[2]], [[xpos,]*testX.shape[1]], [[ypos,]*testX.shape[1]]]), 0, 2), 0, 1), 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = keras.utils.to_categorical(trainY, num_classes)\n",
    "testY = keras.utils.to_categorical(testY, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize data\n",
    "trainX = trainX.astype('float32')/255.0\n",
    "testX = testX.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:46: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ou..., inputs=Tensor(\"ma...)`\n"
     ]
    }
   ],
   "source": [
    "main_input = Input(shape=(image_size, image_size, image_channels), name=\"main_input\")\n",
    "\n",
    "layer1 = Conv2D(16, (3,3), padding='same')(main_input)\n",
    "layer1 = BatchNormalization()(layer1)\n",
    "layer1 = Activation('relu')(layer1)\n",
    "\n",
    "layer2b = Conv2D(32, (1,1), padding='same')(layer1)\n",
    "layer2a = Conv2D(32, (3,3), padding='same')(layer1)\n",
    "layer2a = BatchNormalization()(layer2a)\n",
    "layer2a = Activation('relu')(layer2a)\n",
    "layer2a = Conv2D(32, (3,3), padding='same')(layer2a)\n",
    "layer2 = concatenate([layer2a, layer2b])\n",
    "\n",
    "\n",
    "layer3 = BatchNormalization()(layer2)\n",
    "layer3 = Activation('relu')(layer3)\n",
    "layer3 = Conv2D(32, (3,3), padding='same')(layer3)\n",
    "layer3 = BatchNormalization()(layer3)\n",
    "layer3 = Activation('relu')(layer3)\n",
    "layer3 = Conv2D(32, (3, 3), padding='same')(layer3)\n",
    "layer3 = concatenate([layer3, layer2])\n",
    "\n",
    "layer3 = BatchNormalization()(layer3)\n",
    "layer3 = Activation('relu')(layer3)\n",
    "\n",
    "\n",
    "layer4b = Conv2D(64, (1,1), padding='same')(layer3)\n",
    "layer4a = Conv2D(64, (3, 3), padding='same')(layer3)\n",
    "layer4a = BatchNormalization()(layer4a)\n",
    "layer4a = Activation('relu')(layer4a)\n",
    "layer4a = Conv2D(64, (3, 3), padding='same')(layer4a)\n",
    "layer4 = concatenate([layer4a, layer4b])\n",
    "\n",
    "layer4 = BatchNormalization()(layer4)\n",
    "layer4 = Activation('relu')(layer4)\n",
    "layer4 = AveragePooling2D((8,8), strides=1)(layer4)\n",
    "\n",
    "\n",
    "out = Flatten(name='flatten')(layer4)\n",
    "out = Dense(4096, activation='relu', name='fc1')(out)\n",
    "out = Dropout(0.25)(out)\n",
    "out = Dense(1024, activation='relu', name='fc2')(out)\n",
    "out = Dropout(0.25)(out)\n",
    "out = Dense(10, activation='relu', name='output')(out)\n",
    "\n",
    "model = Model(input=main_input, output=out)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's train the model using Adam\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"../results\"):\n",
    "    os.mkdir(\"../results\")\n",
    "    os.mkdir(\"../results/position\")\n",
    "    os.mkdir(\"../results/position/best_models\")\n",
    "    os.mkdir(\"../results/normal\")\n",
    "    os.mkdir(\"../results/normal/best_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checkpoints and logs\n",
    "\n",
    "if IS_POSITION_BASED:\n",
    "    checkpointer = ModelCheckpoint(filepath=\"../results/position/best_models/fn_model.{epoch:02d}-{val_acc:.6f}.hdf5\", verbose=1, monitor='val_acc', save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "    tf_board = TensorBoard(log_dir='../results/position/logs', histogram_freq=0, write_graph=True, write_images=True)\n",
    "    csv_logger = CSVLogger('../results/position/training.log')\n",
    "else :\n",
    "    checkpointer = ModelCheckpoint(filepath=\"../results/normal/best_models/fn_model.{epoch:02d}-{val_acc:.6f}.hdf5\", verbose=1, monitor='val_acc', save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "    tf_board = TensorBoard(log_dir='../results/normal/logs', histogram_freq=0, write_graph=True, write_images=True)\n",
    "    csv_logger = CSVLogger('../results/normal/training.log')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47500 samples, validate on 2500 samples\n"
     ]
    }
   ],
   "source": [
    "# training network\n",
    "model.fit(trainX, trainY, batch_size=batch_size, epochs=epochs, validation_split=0.05,\n",
    "              callbacks=[early_stopping, checkpointer, tf_board, csv_logger], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing network\n",
    "if IS_POSITION_BASED:\n",
    "    model.save(\"./results/position/best_models/final_model.hdf5\")\n",
    "    score, acc = model.evaluate(testX, testY, batch_size=batch_size)\n",
    "    resultsfile = open(\"./results/position/results.txt\", 'w')\n",
    "    resultsfile.write(\"test_acc: \"+str(acc)+\"\\n\")\n",
    "    resultsfile.write(\"test_score: \" + str(score))\n",
    "    resultsfile.close()\n",
    "else:\n",
    "    model.save(\"./results/normal/best_models/final_model.hdf5\")\n",
    "    score, acc = model.evaluate(testX, testY, batch_size=batch_size)\n",
    "    resultsfile = open(\"./results/normal/results.txt\", 'w')\n",
    "    resultsfile.write(\"test_acc: \"+str(acc)+ \"\\n\")\n",
    "    resultsfile.write(\"test_score: \"+str(score))\n",
    "    resultsfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
